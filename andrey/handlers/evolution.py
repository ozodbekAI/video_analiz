from aiogram import Router, F
from aiogram.types import CallbackQuery, FSInputFile
from aiogram.fsm.context import FSMContext
from aiogram.utils.keyboard import InlineKeyboardBuilder
from callbacks.menu import MenuCallback
from handlers.analysis import ADMIN_IDS
from keyboards.client import get_main_menu_keyboard
from database.crud import (
    create_evolution_analysis,
    get_user,
    get_balanced_evolution_analyses,
    get_channel_analysis_stats,
    get_evolution_prompts,
    update_evolution_step1,
    update_evolution_step2  
)
from services.ai_service import analyze_comments_with_prompt
from services.youtube_service import get_channel_info_by_id
from services.pdf_generator import generate_pdf
from states.evolution import EvolutionFSM
import os
import json
from pathlib import Path
from datetime import datetime
from utils.helpers import clean_html_for_telegram, safe_edit_text
from utils.texts import FEATURE_IN_DEVELOPMENT

router = Router()


def get_channels_keyboard(channels: list):
    builder = InlineKeyboardBuilder()
    
    for channel in channels:
        channel_id = channel['channel_id']
        channel_title = channel['channel_title']
        video_count = channel['video_count']
        
        short_title = channel_title[:25] + "..." if len(channel_title) > 25 else channel_title
        
        status_icon = "âœ…" if channel.get('qualified', False) else "âš ï¸"
        
        builder.button(
            text=f"{status_icon} {short_title} ({video_count})",
            callback_data=f"evolution:select:{channel_id}"
        )
    
    builder.adjust(1)
    builder.row(
        InlineKeyboardBuilder().button(
            text="â†©ï¸ ĞĞ°Ğ·Ğ°Ğ´",
            callback_data=MenuCallback(action="main_menu").pack()
        ).as_markup().inline_keyboard[0][0]
    )
    
    return builder.as_markup()


@router.callback_query(MenuCallback.filter(F.action == "content_evolution"))
async def content_evolution_handler(query: CallbackQuery, state: FSMContext):
    """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº ÑĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ğ¸ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ° Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¾Ğ¹ Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹"""
    user = await get_user(query.from_user.id)
    
    if not user:
        await query.answer("âŒ ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½", show_alert=True)
        return
    
    from database.crud import get_user_verified_channels_with_names
    channels = await get_user_verified_channels_with_names(query.from_user.id)
    
    if not channels:
        await query.message.edit_text(
            "ğŸ“Š <b>Ğ­Ğ’ĞĞ›Ğ®Ğ¦Ğ˜Ğ¯ ĞšĞĞĞ¢Ğ•ĞĞ¢Ğ</b>\n\n"
            "âŒ Ğ£ Ğ²Ğ°Ñ Ğ¿Ğ¾ĞºĞ° Ğ½ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… ĞºĞ°Ğ½Ğ°Ğ»Ğ¾Ğ².\n\n"
            "Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¿Ñ€Ğ¾Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ñ…Ğ¾Ñ‚Ñ Ğ±Ñ‹ Ğ¾Ğ´Ğ¸Ğ½ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· ÑĞ²Ğ¾ĞµĞ³Ğ¾ Ğ²Ğ¸Ğ´ĞµĞ¾, "
            "Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ ÑƒĞ²Ğ¸Ğ´ĞµÑ‚ÑŒ ÑĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ° ĞºĞ°Ğ½Ğ°Ğ»Ğ°.",
            parse_mode="HTML",
            reply_markup=get_main_menu_keyboard()
        )
        return
    
    qualified_channels = []
    for channel in channels:
        stats = await get_channel_analysis_stats(query.from_user.id, channel['channel_id'])
        channel['stats'] = stats
        channel['qualified'] = stats['advanced'] >= 5
        if channel['qualified']:
            qualified_channels.append(channel)
    
    is_admin = query.from_user.id in ADMIN_IDS
    admin_note = "\n\nğŸ‘‘ <i>ĞĞ´Ğ¼Ğ¸Ğ½ Ñ€ĞµĞ¶Ğ¸Ğ¼: Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹ Ğ²ÑĞµ ĞºĞ°Ğ½Ğ°Ğ»Ñ‹</i>" if is_admin else ""
    
    qualified_count = len(qualified_channels)
    total_count = len(channels)
    
    status_message = (
        f"ğŸ“Š <b>Ğ­Ğ’ĞĞ›Ğ®Ğ¦Ğ˜Ğ¯ ĞšĞĞĞ¢Ğ•ĞĞ¢Ğ</b>\n\n"
        f"Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ ĞºĞ°Ğ½Ğ°Ğ» Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° ÑĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ğ¸:\n\n"
        f"ğŸ“º Ğ’ÑĞµĞ³Ğ¾ ĞºĞ°Ğ½Ğ°Ğ»Ğ¾Ğ²: {total_count}\n"
        f"âœ… Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°: {qualified_count}\n"
        f"{admin_note}\n\n"
        f"<i>Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ 5 ÑƒĞ³Ğ»ÑƒĞ±Ğ»ĞµĞ½Ğ½Ñ‹Ñ… Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ² Ğ´Ğ»Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°.</i>"
    )
    
    await query.message.edit_text(
        status_message,
        parse_mode="HTML",
        reply_markup=get_channels_keyboard(channels)
    )
    
    await state.set_state(EvolutionFSM.selecting_channel)


def extract_machine_data_from_file(txt_path: str) -> dict:
    """
    TXT fayldan machine_data JSON ni extract qiladi
    """
    try:
        with open(txt_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # JSON bloklarni qidirish
        if '```json' in content:
            # Markdown JSON bloki
            json_start = content.find('```json') + 7
            json_end = content.find('```', json_start)
            if json_end != -1:
                json_str = content[json_start:json_end].strip()
                return json.loads(json_str)
        
        # To'g'ridan-to'g'ri JSON qidiramiz
        if content.strip().startswith('{'):
            return json.loads(content)
        
        # Agar JSON topilmasa, bo'sh dict qaytaramiz
        return {}
        
    except Exception as e:
        print(f"âš ï¸ Machine data extract qilishda xato: {e}")
        return {}


@router.callback_query(F.data.startswith("evolution:select:"))
async def select_channel_handler(query: CallbackQuery, state: FSMContext):
    channel_id = query.data.split(":", 2)[2]
    await state.update_data(selected_channel_id=channel_id)
    
    is_admin = query.from_user.id in ADMIN_IDS
    admin_badge = "ğŸ‘‘ " if is_admin else ""

    try:
        channel_info = await get_channel_info_by_id(channel_id)
        channel_title = channel_info['title']
    except Exception:
        channel_title = channel_id[:30] + "..."
    
    # ğŸ”¥ YANGI: balanced_analyses dan AI responses ham olamiz
    balanced_analyses = await get_balanced_evolution_analyses(
        user_id=query.from_user.id,
        channel_id=channel_id,
        min_advanced=5,
        total_limit=10
    )

    if not balanced_analyses:
        stats = await get_channel_analysis_stats(query.from_user.id, channel_id)
        
        error_message = (
            f"âŒ <b>ĞĞ•Ğ”ĞĞ¡Ğ¢ĞĞ¢ĞĞ§ĞĞ Ğ”ĞĞĞĞ«Ğ¥</b>\n\n"
            f"ğŸ“º ĞšĞ°Ğ½Ğ°Ğ»: <b>{channel_title}</b>\n"
            f"ğŸ“Š Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°:\n"
            f"  â€¢ Ğ’ÑĞµĞ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²: {stats['total']}\n"
            f"  â€¢ Ğ£Ğ³Ğ»ÑƒĞ±Ğ»ĞµĞ½Ğ½Ñ‹Ñ…: {stats['advanced']}\n"
            f"  â€¢ ĞŸÑ€Ğ¾ÑÑ‚Ñ‹Ñ…: {stats['simple']}\n\n"
            f"<b>Ğ¢Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ:</b>\n"
            f"âœ… ĞœĞ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ <b>5 ÑƒĞ³Ğ»ÑƒĞ±Ğ»ĞµĞ½Ğ½Ñ‹Ñ… Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²</b>\n\n"
            f"<i>ĞŸÑ€Ğ¾Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ ĞµÑ‰Ğµ {max(0, 5 - stats['advanced'])} ÑƒĞ³Ğ»ÑƒĞ±Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹(Ñ…) Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·(Ğ¾Ğ²)</i>"
        )
        
        await query.message.edit_text(
            error_message,
            parse_mode="HTML",
            reply_markup=get_main_menu_keyboard()
        )
        await state.clear()
        return

    advanced_count = sum(1 for video, ai in balanced_analyses if ai.analysis_type == 'advanced')
    simple_count = len(balanced_analyses) - advanced_count
    
    dates = [video.first_comment_date for video, ai in balanced_analyses if video.first_comment_date]
    if dates:
        earliest_date = min(dates).strftime('%d.%m.%Y')
        latest_date = max(dates).strftime('%d.%m.%Y')
        date_range = f"\nğŸ“… ĞŸĞµÑ€Ğ¸Ğ¾Ğ´: {earliest_date} â€” {latest_date}"
    else:
        date_range = ""
    
    await query.message.edit_text(
        f"â³ <b>{admin_badge}Ğ—ĞĞŸĞ£Ğ¡Ğš ĞĞĞĞ›Ğ˜Ğ—Ğ Ğ­Ğ’ĞĞ›Ğ®Ğ¦Ğ˜Ğ˜</b>\n\n"
        f"ğŸ“º ĞšĞ°Ğ½Ğ°Ğ»: <b>{channel_title}</b>\n"
        f"ğŸ“Š ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²: {len(balanced_analyses)} ({advanced_count} ÑƒĞ³Ğ»ÑƒĞ±Ğ». + {simple_count} Ğ¿Ñ€Ğ¾ÑÑ‚.){date_range}\n\n"
        f"ğŸ”„ Ğ­Ñ‚Ğ°Ğ¿ 0/2: ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…...",
        parse_mode="HTML"
    )
    
    try:
        prompts = await get_evolution_prompts()
        
        if not prompts['step1'] or not prompts['step2']:
            await query.message.edit_text(
                "âŒ <b>ĞĞ¨Ğ˜Ğ‘ĞšĞ ĞšĞĞĞ¤Ğ˜Ğ“Ğ£Ğ ĞĞ¦Ğ˜Ğ˜</b>\n\n"
                "ĞŸÑ€Ğ¾Ğ¼Ğ¿Ñ‚Ñ‹ Ğ´Ğ»Ñ ÑĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ğ¸ Ğ½Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ñ‹ Ğ² ÑĞ¸ÑÑ‚ĞµĞ¼Ğµ.",
                parse_mode="HTML",
                reply_markup=get_main_menu_keyboard()
            )
            await state.clear()
            return

        all_analyses = []
        video_ids_used = []
        
        for idx, (video, ai_response) in enumerate(balanced_analyses, 1):
            video_id = video.id
            video_url = video.video_url
            analysis_type = ai_response.analysis_type
            processed_date = video.processed_at.strftime('%d.%m.%Y')
            
            machine_data = None
            if ai_response.machine_data:
                # Agar DBda JSON saqlangan bo'lsa
                if isinstance(ai_response.machine_data, dict):
                    machine_data = ai_response.machine_data
                elif isinstance(ai_response.machine_data, str):
                    try:
                        machine_data = json.loads(ai_response.machine_data)
                    except:
                        pass
            
            # Fallback: TXT fayldan o'qish (eski versiya uchun)
            if not machine_data and ai_response.txt_file_path and os.path.exists(ai_response.txt_file_path):
                machine_data = extract_machine_data_from_file(ai_response.txt_file_path)
            
            # Agar machine_data topilmasa, response_text ishlatamiz
            if machine_data:
                content = json.dumps(machine_data, ensure_ascii=False, indent=2)
                data_source = "JSON"
            elif ai_response.response_text:
                content = ai_response.response_text
                data_source = "TEXT"
            else:
                print(f"âš ï¸ Video {video_id} uchun ma'lumot topilmadi")
                continue
            
            all_analyses.append({
                'number': idx,
                'date': processed_date,
                'video_url': video_url,
                'type': analysis_type,
                'content': content,
                'data_source': data_source
            })
            video_ids_used.append(video_id)
        
        if len(all_analyses) < 5:
            await query.message.edit_text(
                f"âŒ <b>ĞĞ¨Ğ˜Ğ‘ĞšĞ Ğ—ĞĞ“Ğ Ğ£Ğ—ĞšĞ˜</b>\n\n"
                f"Ğ£Ğ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ {len(all_analyses)} Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ².\n"
                f"Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ 5.",
                parse_mode="HTML",
                reply_markup=get_main_menu_keyboard()
            )
            await state.clear()
            return

        user = await get_user(query.from_user.id)
        
        evolution = await create_evolution_analysis(
            user_id=user.user_id,
            channel_id=channel_id,
            channel_title=channel_title,
            videos_analyzed=len(all_analyses),
            video_ids_used=video_ids_used
        )
        
        await query.message.edit_text(
            f"â³ <b>{admin_badge}ĞĞĞĞ›Ğ˜Ğ— Ğ­Ğ’ĞĞ›Ğ®Ğ¦Ğ˜Ğ˜</b>\n\n"
            f"ğŸ“º ĞšĞ°Ğ½Ğ°Ğ»: <b>{channel_title}</b>\n"
            f"âœ… Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ¾: {len(all_analyses)} Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²\n"
            f"ğŸ”„ Ğ­Ñ‚Ğ°Ğ¿ 1/2: ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…...",
            parse_mode="HTML"
        )
        
        # ğŸ”¥ YANGI: combined_text ni yaratishda data_source ni ko'rsatamiz
        combined_text = ""
        for analysis in all_analyses:
            type_label = "Ğ£Ğ“Ğ›Ğ£Ğ‘Ğ›Ğ•ĞĞĞ«Ğ™" if analysis['type'] == 'advanced' else "ĞŸĞ ĞĞ¡Ğ¢ĞĞ™"
            data_label = f" [{analysis['data_source']}]"
            
            combined_text += f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â•‘ ĞĞĞĞ›Ğ˜Ğ— #{analysis['number']} ({type_label}{data_label}) Ğ¾Ñ‚ {analysis['date']}
â•‘ Ğ’Ğ¸Ğ´ĞµĞ¾: {analysis['video_url']}
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

{analysis['content']}

{'=' * 80}

"""
        
        await query.message.edit_text(
            f"â³ <b>{admin_badge}ĞĞĞĞ›Ğ˜Ğ— Ğ­Ğ’ĞĞ›Ğ®Ğ¦Ğ˜Ğ˜</b>\n\n"
            f"ğŸ“º ĞšĞ°Ğ½Ğ°Ğ»: <b>{channel_title}</b>\n"
            f"âœ… ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ¾: {len(all_analyses)} Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²\n"
            f"ğŸ”„ Ğ­Ñ‚Ğ°Ğ¿ 1/2: AI Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°...\n\n"
            f"<i>Ğ­Ñ‚Ğ¾ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ·Ğ°Ğ½ÑÑ‚ÑŒ 1-2 Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñ‹</i>",
            parse_mode="HTML"
        )
        
        step1_response = await analyze_comments_with_prompt(
            combined_text,
            prompts['step1'].prompt_text
        )
        
        await update_evolution_step1(evolution.id, step1_response)

        await query.message.edit_text(
            f"â³ <b>{admin_badge}ĞĞĞĞ›Ğ˜Ğ— Ğ­Ğ’ĞĞ›Ğ®Ğ¦Ğ˜Ğ˜</b>\n\n"
            f"ğŸ“º ĞšĞ°Ğ½Ğ°Ğ»: <b>{channel_title}</b>\n"
            f"âœ… Ğ­Ñ‚Ğ°Ğ¿ 1/2 Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½\n"
            f"ğŸ”„ Ğ­Ñ‚Ğ°Ğ¿ 2/2: Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ÑĞ¸Ğ½Ñ‚ĞµĞ·...\n\n"
            f"<i>Ğ­Ñ‚Ğ¾ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ·Ğ°Ğ½ÑÑ‚ÑŒ 1-2 Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñ‹</i>",
            parse_mode="HTML"
        )
        
        final_response = await analyze_comments_with_prompt(
            step1_response,
            prompts['step2'].prompt_text
        )
        
        await query.message.edit_text(
            f"â³ <b>{admin_badge}ĞĞĞĞ›Ğ˜Ğ— Ğ­Ğ’ĞĞ›Ğ®Ğ¦Ğ˜Ğ˜</b>\n\n"
            f"ğŸ“º ĞšĞ°Ğ½Ğ°Ğ»: <b>{channel_title}</b>\n"
            f"âœ… ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½\n"
            f"ğŸ“„ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ°...",
            parse_mode="HTML"
        )
        
        evolution_dir = Path(f"reports/{user.user_id}/evolution")
        evolution_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        txt_filename = f"evolution_{channel_id}_{timestamp}.txt"
        txt_path = evolution_dir / txt_filename
        
        with open(txt_path, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("Ğ­Ğ’ĞĞ›Ğ®Ğ¦Ğ˜Ğ¯ ĞšĞĞĞ¢Ğ•ĞĞ¢Ğ ĞšĞĞĞĞ›Ğ\n")
            f.write("=" * 80 + "\n\n")
            f.write(f"ĞšĞ°Ğ½Ğ°Ğ»: {channel_title}\n")
            f.write(f"ĞšĞ°Ğ½Ğ°Ğ» ID: {channel_id}\n")
            f.write(f"ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²: {len(all_analyses)} ({advanced_count} ÑƒĞ³Ğ»ÑƒĞ±Ğ». + {simple_count} Ğ¿Ñ€Ğ¾ÑÑ‚.)\n")
            if date_range:
                f.write(f"ĞŸĞµÑ€Ğ¸Ğ¾Ğ´: {earliest_date} â€” {latest_date}\n")
            f.write(f"Ğ”Ğ°Ñ‚Ğ° Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ°: {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}\n")
            f.write("\n" + "=" * 80 + "\n\n")
            f.write(final_response)

        fake_video_url = f"https://www.youtube.com/channel/{channel_id}"
        pdf_file = generate_pdf(
            final_response, 
            fake_video_url, 
            f"evolution_{channel_id}"
        )
        
        pdf_filename = f"evolution_{channel_id}_{timestamp}.pdf"
        pdf_path = evolution_dir / pdf_filename
        os.rename(pdf_file, str(pdf_path))

        analysis_period = f"{earliest_date} â€” {latest_date}" if dates else "Ğ½ĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ğ¹ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´"
        await update_evolution_step2(
            evolution.id,
            final_response,
            pdf_path=str(pdf_path),
            txt_path=str(txt_path),
            analysis_period=analysis_period
        )

        safe_summary = clean_html_for_telegram(
            f"âœ… <b>{admin_badge}ĞĞĞĞ›Ğ˜Ğ— Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•Ğ!</b>\n\n"
            f"ğŸ“º {channel_title}\n"
            f"ğŸ“Š ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²: {len(all_analyses)} ({advanced_count} ÑƒĞ³Ğ»ÑƒĞ±Ğ». + {simple_count} Ğ¿Ñ€Ğ¾ÑÑ‚.)\n"
            f"ğŸ“… {analysis_period}"
        )
        
        await query.message.edit_text(safe_summary, parse_mode="HTML")
        
        await query.message.answer_document(
            FSInputFile(pdf_path),
            caption=f"ğŸ“Š <b>{admin_badge}Ğ­Ğ²Ğ¾Ğ»ÑÑ†Ğ¸Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ°</b>\n\n"
                    f"ğŸ“º {channel_title}\n"
                    f"ğŸ“ˆ ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²: {len(all_analyses)}\n"
                    f"ğŸ“… {analysis_period}\n"
                    f"ğŸ• {datetime.now().strftime('%d.%m.%Y %H:%M')}",
            parse_mode="HTML"
        )
        
        await query.message.answer(
            "âœ… <b>Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾!</b>\n\nĞ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ:",
            reply_markup=get_main_menu_keyboard(),
            parse_mode="HTML"
        )
        
        await state.clear()
    
    except Exception as e:
        import traceback
        print(f"âŒ EVOLUTION ERROR:\n{traceback.format_exc()}")
        
        safe_error = clean_html_for_telegram(
            f"âŒ <b>ĞĞ¨Ğ˜Ğ‘ĞšĞ</b>\n\n{str(e)[:200]}"
        )
        
        await query.message.edit_text(
            safe_error,
            parse_mode="HTML",
            reply_markup=get_main_menu_keyboard()
        )
        await state.clear()

async def universal_analysis_handler(
    query: CallbackQuery,
    state: FSMContext,
    analysis_type: str
):
    """
    Universal handler:
    audience_map
    content_prediction
    channel_diagnostics
    content_ideas
    viral_potential
    iterative_ideas
    """
    await state.clear()

    await safe_edit_text(
        query,
        FEATURE_IN_DEVELOPMENT,
        reply_markup=get_main_menu_keyboard(),
        parse_mode="HTML"
    )