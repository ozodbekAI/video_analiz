#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""YouTube Parser - –ì–∏–±—Ä–∏–¥–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Shorts"""

import sys
import time
from pathlib import Path
from datetime import datetime
from typing import List, Optional

from youtube_api import YouTubeAPI
from data_models import ParsingResult
from utils import extract_video_id, validate_video_id, create_results_dir, get_unique_filename, format_number, format_duration, log_errors
import settings


class YouTubeParser:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –ø–∞—Ä—Å–µ—Ä–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Shorts"""
    
    def __init__(self):
        self.api = YouTubeAPI()
        self.results_dir = create_results_dir()
    
    @log_errors
    def parse_video(self, video_id: str, video_type: str = "video", max_comments: int = 0) -> Optional[ParsingResult]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –≤–∏–¥–µ–æ –∏–ª–∏ Shorts"""
        print(f"\n{'='*60}")
        
        if video_type == "shorts":
            print(f"üé¨ –û–±—Ä–∞–±–æ—Ç–∫–∞ SHORTS: {video_id}")
        else:
            print(f"üé¨ –û–±—Ä–∞–±–æ—Ç–∫–∞ –í–ò–î–ï–û: {video_id}")
        
        print(f"{'='*60}")
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è ID
        if not validate_video_id(video_id):
            print(f"‚ùå –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π ID –≤–∏–¥–µ–æ: {video_id}")
            return None
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤–∏–¥–µ–æ
        print(f"üìπ –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏...")
        video_info = self.api.get_video_info(video_id, video_type)
        
        if not video_info:
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é")
            return None
        
        print(f"   üìù –ù–∞–∑–≤–∞–Ω–∏–µ: {video_info.title[:80]}..." if len(video_info.title) > 80 else f"   üìù –ù–∞–∑–≤–∞–Ω–∏–µ: {video_info.title}")
        print(f"   üì∫ –ö–∞–Ω–∞–ª: {video_info.channel_title}")
        print(f"   üëÅ –ü—Ä–æ—Å–º–æ—Ç—Ä–æ–≤: {format_number(video_info.view_count)}")
        print(f"   ‚ù§Ô∏è –õ–∞–π–∫–æ–≤: {format_number(video_info.like_count)}")
        print(f"   üí¨ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –ø–æ API: {format_number(video_info.comment_count)}")
        print(f"   ‚è± –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {video_info.duration}")
        
        if video_info.is_shorts or video_info.duration_seconds <= 60:
            print(f"   üéØ –¢–∏–ø: YouTube Shorts")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, —Å–∫–æ–ª—å–∫–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ —Å–æ–±–∏—Ä–∞—Ç—å
        if max_comments <= 0:
            max_to_collect = min(video_info.comment_count, 10000)
        else:
            max_to_collect = min(max_comments, video_info.comment_count)
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
        comments = self.api.get_video_comments(video_id, video_type, max_to_collect)
        
        if not comments:
            print(f"   ‚ÑπÔ∏è  –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            comments = []
        else:
            print(f"   üí¨ –ù–∞–π–¥–µ–Ω–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤: {format_number(len(comments))}")
        
        # –†–∞—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        print(f"üìä –†–∞—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏...")
        from utils import StatisticsCalculator
        statistics = StatisticsCalculator.calculate_video_stats(video_info, comments, video_type)
        
        return ParsingResult(
            video=video_info,
            comments=comments,
            statistics=statistics,
            metadata={
                'video_id': video_id,
                'video_type': video_type,
                'api_requests': self.api.request_count,
                'parsing_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'comments_collected': len(comments),
                'comments_total': video_info.comment_count,
                'collection_ratio': f"{len(comments)}/{video_info.comment_count} ({len(comments)/video_info.comment_count*100:.1f}%)" if video_info.comment_count > 0 else "N/A"
            }
        )
    
    @log_errors
    def save_enriched_txt(self, result: ParsingResult) -> Optional[Path]:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –æ–±–æ–≥–∞—â–µ–Ω–Ω–æ–º TXT —Ñ–æ—Ä–º–∞—Ç–µ"""
        if not result:
            return None
        
        video = result.video
        stats = result.statistics
        metadata = result.metadata
        
        filename = get_unique_filename(video.id, video.video_type, "txt")
        
        with open(filename, 'w', encoding=settings.ENCODING) as f:
            f.write("=" * 80 + "\n")
            
            if video.is_shorts:
                f.write("üé¨ YouTube SHORTS ANALYSIS REPORT\n")
            else:
                f.write("üìπ YouTube VIDEO ANALYSIS REPORT\n")
            
            f.write("=" * 80 + "\n\n")
            
            # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            f.write("üìã –û–°–ù–û–í–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø\n")
            f.write("-" * 40 + "\n")
            f.write(f"–¢–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {'YouTube Shorts' if video.is_shorts else '–û–±—ã—á–Ω–æ–µ –≤–∏–¥–µ–æ'}\n")
            f.write(f"–ù–∞–∑–≤–∞–Ω–∏–µ: {video.title}\n")
            f.write(f"–ö–∞–Ω–∞–ª: {video.channel_title}\n")
            f.write(f"–û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ: {video.published_at}\n")
            f.write(f"–ü—Ä–æ—Å–º–æ—Ç—Ä–æ–≤: {format_number(video.view_count)}\n")
            f.write(f"–õ–∞–π–∫–æ–≤: {format_number(video.like_count)}\n")
            f.write(f"–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ (–ø–æ API): {format_number(video.comment_count)}\n")
            f.write(f"–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {video.duration}\n")
            f.write("\n")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            f.write("üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –í–ò–î–ï–û\n")
            f.write("-" * 40 + "\n")
            video_stats = stats['video_info']
            f.write(f"–í–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç—å (engagement rate): {video_stats['engagement_rate']:.2f}%\n\n")
            
            comment_stats = stats['comment_statistics']
            f.write("üí¨ –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ö–û–ú–ú–ï–ù–¢–ê–†–ò–ï–í\n")
            f.write("-" * 40 + "\n")
            f.write(f"–í—Å–µ–≥–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤: {format_number(comment_stats['total_comments'])}\n")
            f.write(f"–û—Å–Ω–æ–≤–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤: {format_number(comment_stats['total_top_level'])}\n")
            f.write(f"–û—Ç–≤–µ—Ç–æ–≤: {format_number(comment_stats['total_replies'])}\n")
            f.write(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞–≤—Ç–æ—Ä–æ–≤: {format_number(comment_stats['unique_authors'])}\n")
            f.write(f"–í—Å–µ–≥–æ –ª–∞–π–∫–æ–≤ –Ω–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö: {format_number(comment_stats['total_likes'])}\n")
            f.write(f"–°—Ä–µ–¥–Ω–µ–µ –ª–∞–π–∫–æ–≤ –Ω–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: {comment_stats['avg_likes_per_comment']:.2f}\n\n")
            
            # –°–∞–º—ã–π –ø–æ–ø—É–ª—è—Ä–Ω—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π
            if comment_stats.get('most_liked_comment'):
                mlc = comment_stats['most_liked_comment']
                f.write("‚≠ê –°–ê–ú–´–ô –ü–û–ü–£–õ–Ø–†–ù–´–ô –ö–û–ú–ú–ï–ù–¢–ê–†–ò–ô\n")
                f.write("-" * 40 + "\n")
                f.write(f"–ê–≤—Ç–æ—Ä: {mlc['author']}\n")
                f.write(f"–õ–∞–π–∫–æ–≤: {mlc['likes']}\n")
                f.write(f"–¢–µ–∫—Å—Ç: {mlc['text']}\n\n")
            
            # –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
            f.write("=" * 80 + "\n\n")
            f.write("üí≠ –ö–û–ú–ú–ï–ù–¢–ê–†–ò–ò\n")
            f.write("=" * 80 + "\n\n")
            
            if not result.comments:
                f.write("(–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç)\n")
            else:
                for idx, comment in enumerate(result.comments[:100], 1):  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 100 –¥–ª—è —Ñ–∞–π–ª–∞
                    f.write(f"\n{idx}. {comment.author}\n")
                    f.write(f"   ‚ù§Ô∏è {comment.like_count} –ª–∞–π–∫–æ–≤\n")
                    f.write(f"   üìÖ {comment.published_at}\n")
                    f.write(f"   üí¨ {comment.text_clean[:200]}...\n" if len(comment.text_clean) > 200 else f"   üí¨ {comment.text_clean}\n")
            
            # –§—É—Ç–µ—Ä
            f.write("\n")
            f.write("=" * 80 + "\n")
            f.write(f"üìÖ –û—Ç—á–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}\n")
            f.write(f"üî¢ API –∑–∞–ø—Ä–æ—Å–æ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ: {self.api.request_count}\n")
            f.write(f"üéØ –¢–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {'YouTube Shorts' if video.is_shorts else '–û–±—ã—á–Ω–æ–µ –≤–∏–¥–µ–æ'}\n")
            f.write("=" * 80 + "\n")
        
        print(f"üíæ –û–±–æ–≥–∞—â–µ–Ω–Ω—ã–π TXT —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filename.name}")
        return filename
    
    @log_errors
    def parse_from_file(self, filepath: str = None, max_comments_per_video: int = 0) -> List[ParsingResult]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –≤–∏–¥–µ–æ –∏–∑ —Ñ–∞–π–ª–∞"""
        filepath = filepath or settings.URLS_FILE
        results = []
        
        try:
            if not Path(filepath).exists():
                print(f"‚ùå –§–∞–π–ª {filepath} –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return results
            
            with open(filepath, 'r', encoding=settings.ENCODING) as f:
                urls = [line.strip() for line in f if line.strip() and not line.startswith('#')]
            
            if not urls:
                print(f"‚ùå –í —Ñ–∞–π–ª–µ {filepath} –Ω–µ—Ç URL'–æ–≤")
                return results
            
            print(f"\nüöÄ –ü–∞—Ä—Å–∏–Ω–≥ {len(urls)} –≤–∏–¥–µ–æ –∏–∑ —Ñ–∞–π–ª–∞...")
            
            for idx, url in enumerate(urls, 1):
                print(f"\n[{idx}/{len(urls)}] –û–±—Ä–∞–±–æ—Ç–∫–∞ URL: {url}")
                
                video_id, video_type = extract_video_id(url)
                
                if not video_id:
                    print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å ID –∏–∑ URL: {url}")
                    continue
                
                if not validate_video_id(video_id):
                    print(f"‚ö†Ô∏è  ID –≤—ã–≥–ª—è–¥–∏—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º: {video_id}")
                    continue
                
                result = self.parse_video(video_id, video_type, max_comments_per_video)
                if result:
                    self.save_enriched_txt(result)
                    results.append(result)
                    time.sleep(2)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –≤–∏–¥–µ–æ
            
            print(f"\n‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(results)} –≤–∏–¥–µ–æ")
            
        except FileNotFoundError:
            print(f"‚ùå –§–∞–π–ª {filepath} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ —Ñ–∞–π–ª–∞: {e}")
        
        return results


def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞"""
    parser = YouTubeParser()
    
    if len(sys.argv) > 1:
        # –†–µ–∂–∏–º –æ–¥–Ω–æ–≥–æ –≤–∏–¥–µ–æ
        url = sys.argv[1]
        
        video_id, video_type = extract_video_id(url)
        
        if not video_id:
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å ID –∏–∑ URL: {url}")
            return
        
        if not validate_video_id(video_id):
            print(f"‚ö†Ô∏è  ID –≤—ã–≥–ª—è–¥–∏—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º: {video_id}")
            response = input("   –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å? (y/n): ")
            if response.lower() != 'y':
                return
        
        max_comments = 0
        if len(sys.argv) > 2 and sys.argv[2].isdigit():
            max_comments = int(sys.argv[2])
        
        result = parser.parse_video(video_id, video_type, max_comments)
        if result:
            parser.save_enriched_txt(result)
    else:
        # –†–µ–∂–∏–º –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞
        parser.parse_from_file()


if __name__ == "__main__":
    main()
